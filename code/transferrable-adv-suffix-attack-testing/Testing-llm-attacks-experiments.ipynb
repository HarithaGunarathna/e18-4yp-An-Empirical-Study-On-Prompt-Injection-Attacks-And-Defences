{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b055b267-2004-4673-b3e0-928aa283f47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llm-attacks'...\n",
      "remote: Enumerating objects: 154, done.\u001b[K\n",
      "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
      "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
      "remote: Total 154 (delta 64), reused 39 (delta 39), pack-reused 58\u001b[K\n",
      "Receiving objects: 100% (154/154), 116.61 KiB | 2.48 MiB/s, done.\n",
      "Resolving deltas: 100% (78/78), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/llm-attacks/llm-attacks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3046dea-d384-4d33-b141-97d394c58263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/llm-attacks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd llm-attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfffb6a3-e697-460a-9bdc-bbffde534d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/llm-attacks\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==4.28.1 (from llm-attacks==0.0.1)\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml_collections (from llm-attacks==0.0.1)\n",
      "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fschat==0.2.20 (from llm-attacks==0.0.1)\n",
      "  Downloading fschat-0.2.20-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting accelerate (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting fastapi (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading fastapi-0.110.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.28.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.20->llm-attacks==0.0.1) (0.27.0)\n",
      "Collecting markdown2[all] (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting nh3 (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading nh3-0.2.17-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.20->llm-attacks==0.0.1) (1.26.3)\n",
      "Collecting peft (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.20->llm-attacks==0.0.1) (3.0.43)\n",
      "Collecting pydantic<=2.0 (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading pydantic-2.0-py3-none-any.whl.metadata (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.20->llm-attacks==0.0.1) (2.31.0)\n",
      "Collecting rich>=10.0.0 (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentencepiece (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting shortuuid (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tiktoken (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tokenizers>=0.12.1 (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.20->llm-attacks==0.0.1) (2.2.1)\n",
      "Collecting uvicorn (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting wandb (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->llm-attacks==0.0.1) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.1->llm-attacks==0.0.1)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->llm-attacks==0.0.1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->llm-attacks==0.0.1) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.28.1->llm-attacks==0.0.1)\n",
      "  Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers>=0.12.1 (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->llm-attacks==0.0.1) (4.65.0)\n",
      "Collecting absl-py (from ml_collections->llm-attacks==0.0.1)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections->llm-attacks==0.0.1) (1.16.0)\n",
      "Collecting contextlib2 (from ml_collections->llm-attacks==0.0.1)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1->llm-attacks==0.0.1) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1->llm-attacks==0.0.1) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.0->fschat==0.2.20->llm-attacks==0.0.1) (0.2.5)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<=2.0->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.0.1 (from pydantic<=2.0->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading pydantic_core-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.0.0->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.20->llm-attacks==0.0.1) (2.15.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->fschat==0.2.20->llm-attacks==0.0.1) (5.9.0)\n",
      "Collecting safetensors>=0.3.1 (from accelerate->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fschat==0.2.20->llm-attacks==0.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fschat==0.2.20->llm-attacks==0.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fschat==0.2.20->llm-attacks==0.0.1) (3.1.3)\n",
      "Collecting pydantic<=2.0 (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ffmpy (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.16.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.16.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->fschat==0.2.20->llm-attacks==0.0.1) (2.1.3)\n",
      "Collecting matplotlib~=3.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting orjson~=3.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas<3.0,>=1.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio->fschat==0.2.20->llm-attacks==0.0.1) (10.2.0)\n",
      "INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.28.2-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.28.1-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.28.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.27.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.15.1 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.15.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.26.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.25.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.15.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.15.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.24.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.14.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.14.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "INFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.23.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.22.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.13.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.13.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.21.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.12.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.12.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.20.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.11.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.11.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.20.0-py3-none-any.whl.metadata (15 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading gradio-4.19.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.10.1 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.19.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.10.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.19.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.18.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.17.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.9.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.8.1 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.8.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.8.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading gradio-4.11.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting gradio-client==0.7.3 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.7.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.10.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.9.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.9.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting gradio-client==0.7.2 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.7.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.8.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting gradio-client==0.7.1 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.7.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting gradio-client==0.7.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gradio (from fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.4.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.1.2-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.0.2-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.0.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-4.0.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting gradio-client==0.6.1 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydub (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.20->llm-attacks==0.0.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.20->llm-attacks==0.0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.20->llm-attacks==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.20->llm-attacks==0.0.1) (2024.2.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->fschat==0.2.20->llm-attacks==0.0.1) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->fschat==0.2.20->llm-attacks==0.0.1) (0.14.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->fschat==0.2.20->llm-attacks==0.0.1) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->fschat==0.2.20->llm-attacks==0.0.1) (1.0.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->fschat==0.2.20->llm-attacks==0.0.1) (1.3.1)\n",
      "Collecting wavedrom (from markdown2[all]->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0 (from wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setproctitle (from wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->fschat==0.2.20->llm-attacks==0.0.1) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (0.12.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m695.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->fschat==0.2.20->llm-attacks==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fschat==0.2.20->llm-attacks==0.0.1) (1.3.0)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->fschat==0.2.20->llm-attacks==0.0.1)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.20->llm-attacks==0.0.1) (0.10.6)\n",
      "Downloading fschat-0.2.20-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nh3-0.2.17-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.1/777.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: ml_collections, ffmpy, wavedrom\n",
      "  Building wheel for ml_collections (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml_collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=5b98093ff0de721968a602527d8a3494544155c87d6deef866d20d559565d97d\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5582 sha256=6ff0b5287c699f395973c69819cf6dc15ce6e9d8277e96b266fab968a079bdfd\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
      "  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=b5cce489562bfc8c6a443652ba4df5c971cfb911a691d56caf04309c716464af\n",
      "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
      "Successfully built ml_collections ffmpy wavedrom\n",
      "Installing collected packages: tokenizers, sentencepiece, pydub, nh3, ffmpy, appdirs, websockets, uvicorn, tzdata, svgwrite, smmap, shortuuid, setproctitle, sentry-sdk, semantic-version, safetensors, regex, python-multipart, pyparsing, pydantic, protobuf, orjson, mdurl, markdown2, kiwisolver, importlib-resources, fonttools, docker-pycreds, cycler, contourpy, contextlib2, aiofiles, absl-py, wavedrom, tiktoken, starlette, pandas, ml_collections, matplotlib, markdown-it-py, huggingface-hub, gitdb, transformers, rich, gradio-client, GitPython, fastapi, accelerate, wandb, peft, altair, gradio, fschat, llm-attacks\n",
      "  Running setup.py develop for llm-attacks\n",
      "Successfully installed GitPython-3.1.43 absl-py-2.1.0 accelerate-0.29.3 aiofiles-23.2.1 altair-5.3.0 appdirs-1.4.4 contextlib2-21.6.0 contourpy-1.2.1 cycler-0.12.1 docker-pycreds-0.4.0 fastapi-0.110.2 ffmpy-0.3.2 fonttools-4.51.0 fschat-0.2.20 gitdb-4.0.11 gradio-3.50.2 gradio-client-0.6.1 huggingface-hub-0.22.2 importlib-resources-6.4.0 kiwisolver-1.4.5 llm-attacks-0.0.1 markdown-it-py-3.0.0 markdown2-2.4.13 matplotlib-3.8.4 mdurl-0.1.2 ml_collections-0.1.1 nh3-0.2.17 orjson-3.10.1 pandas-2.2.2 peft-0.10.0 protobuf-4.25.3 pydantic-1.10.15 pydub-0.25.1 pyparsing-3.1.2 python-multipart-0.0.9 regex-2024.4.28 rich-13.7.1 safetensors-0.4.3 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.0.1 setproctitle-1.3.3 shortuuid-1.0.13 smmap-5.0.1 starlette-0.37.2 svgwrite-1.4.3 tiktoken-0.6.0 tokenizers-0.13.3 transformers-4.28.1 tzdata-2024.1 uvicorn-0.29.0 wandb-0.16.6 wavedrom-2.0.3.post3 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "real\t0m43.338s\n",
      "user\t0m23.509s\n",
      "sys\t0m4.181s\n"
     ]
    }
   ],
   "source": [
    "!time pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff12161e-1277-4faf-bc80-25dbff402001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot\n",
      "  Downloading livelossplot-0.5.5-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from livelossplot) (3.8.4)\n",
      "Collecting bokeh (from livelossplot)\n",
      "  Downloading bokeh-3.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.26.3)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (23.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (2.2.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (10.2.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (6.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (6.4)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh->livelossplot)\n",
      "  Downloading xyzservices-2024.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh->livelossplot) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
      "Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
      "Downloading bokeh-3.4.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m991.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xyzservices-2024.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xyzservices, bokeh, livelossplot\n",
      "Successfully installed bokeh-3.4.1 livelossplot-0.5.5 xyzservices-2024.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87b91fc-1a9b-4cae-a89c-e1910f1d57aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe84e68-0d11-4fdf-883e-afd9a9127b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /opt/conda/lib/python3.10/site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.9.0)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.43)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2024.2.2)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.5)\n",
      "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: pfzy, InquirerPy\n",
      "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef29939c-5858-485f-bc5d-3b0ea97a861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98258036-d46d-481d-b182-57a51c31c036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
      "Fetching 16 files:   0%|                                 | 0/16 [00:00<?, ?it/s]downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/model-00001-of-00002.safetensors to /root/.cache/huggingface/hub/tmpkn754zce\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.58 MB. The target location /root/.cache/huggingface/hub only has 3111.31 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.58 MB. The target location /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/blobs only has 3111.31 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.58 MB. The target location . only has 3111.31 MB free disk space.\n",
      "  warnings.warn(\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/README.md to /root/.cache/huggingface/hub/tmpe9ocurao\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/model-00002-of-00002.safetensors to /root/.cache/huggingface/hub/tmp8d19_vwd\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.30 MB. The target location /root/.cache/huggingface/hub only has 3111.30 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.30 MB. The target location /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/blobs only has 3111.30 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.30 MB. The target location . only has 3111.30 MB free disk space.\n",
      "  warnings.warn(\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/LICENSE.txt to /root/.cache/huggingface/hub/tmpfz7_jp0h\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/.gitattributes to /root/.cache/huggingface/hub/tmptnq3_9qs\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/USE_POLICY.md to /root/.cache/huggingface/hub/tmpampuuvi8\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/generation_config.json to /root/.cache/huggingface/hub/tmpusbfgjyg\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/config.json to /root/.cache/huggingface/hub/tmpmjc3pah4\n",
      "\n",
      "README.md: 100%|███████████████████████████| 22.3k/22.3k [00:00<00:00, 51.4MB/s]\u001b[A\n",
      "\n",
      "LICENSE.txt: 100%|█████████████████████████| 7.02k/7.02k [00:00<00:00, 32.9MB/s]\u001b[A\n",
      "\n",
      "USE_POLICY.md: 100%|███████████████████████| 4.77k/4.77k [00:00<00:00, 15.9MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|██████████████████| 188/188 [00:00<00:00, 1.47MB/s]\u001b[A\n",
      "\n",
      ".gitattributes: 100%|██████████████████████| 1.52k/1.52k [00:00<00:00, 12.4MB/s]\u001b[A\n",
      "Fetching 16 files:   6%|█▌                       | 1/16 [00:00<00:05,  2.63it/s]downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/model.safetensors.index.json to /root/.cache/huggingface/hub/tmp2lmhif4k\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 614/614 [00:00<00:00, 4.73MB/s]\u001b[A\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/pytorch_model-00001-of-00002.bin to /root/.cache/huggingface/hub/tmp7i6y7wr_\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.63 MB. The target location /root/.cache/huggingface/hub only has 3111.22 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.63 MB. The target location /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/blobs only has 3111.22 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.63 MB. The target location . only has 3111.22 MB free disk space.\n",
      "  warnings.warn(\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/special_tokens_map.json to /root/.cache/huggingface/hub/tmp178p8sjk\n",
      "\n",
      "model.safetensors.index.json: 100%|████████| 26.8k/26.8k [00:00<00:00, 68.8MB/s]\u001b[A\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/pytorch_model.bin.index.json to /root/.cache/huggingface/hub/tmpuncxeh7c\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.json to /root/.cache/huggingface/hub/tmpvaah2cyy\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 414/414 [00:00<00:00, 2.93MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin.index.json: 100%|████████| 26.8k/26.8k [00:00<00:00, 22.5MB/s]\u001b[A\n",
      "downloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.model to /root/.cache/huggingface/hub/tmpxdtz9ag4\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/1.84M [00:00<?, ?B/s]\u001b[Adownloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/tokenizer_config.json to /root/.cache/huggingface/hub/tmpmuv461lm\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer_config.json: 100%|███████████████| 1.62k/1.62k [00:00<00:00, 12.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|             | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.model: 100%|███████████████████████| 500k/500k [00:00<00:00, 5.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "tokenizer.json: 100%|██████████████████████| 1.84M/1.84M [00:00<00:00, 10.4MB/s]\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|             | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 10.5M/9.98G [00:00<03:22, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 21.0M/9.98G [00:00<06:16, 26.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|    | 10.5M/3.50G [00:01<06:50, 8.51MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 10.5M/9.98G [00:01<22:42, 7.32MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 21.0M/9.98G [00:01<10:59, 15.1MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 31.5M/9.98G [00:01<08:56, 18.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 31.5M/9.98G [00:01<06:52, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 52.4M/9.98G [00:02<04:35, 36.0MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 41.9M/9.98G [00:01<08:13, 20.1MB/s]\u001b[Adownloading https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/f5db02db724555f92da89c216ac04704f23d4590/pytorch_model-00002-of-00002.bin to /root/.cache/huggingface/hub/tmp2uwx6yed\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.32 MB. The target location /root/.cache/huggingface/hub only has 2871.97 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.32 MB. The target location /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/blobs only has 2871.97 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.32 MB. The target location . only has 2871.97 MB free disk space.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 62.9M/9.98G [00:02<05:07, 32.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   1%|    | 21.0M/3.50G [00:02<06:59, 8.29MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 73.4M/9.98G [00:02<04:15, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|             | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 52.4M/9.98G [00:02<08:52, 18.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 83.9M/9.98G [00:02<03:36, 45.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|    | 10.5M/3.50G [00:00<00:53, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 94.4M/9.98G [00:02<03:12, 51.5MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 62.9M/9.98G [00:02<06:59, 23.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|     | 105M/9.98G [00:03<03:02, 54.0MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 73.4M/9.98G [00:03<05:49, 28.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|     | 115M/9.98G [00:03<02:41, 61.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 31.5M/3.50G [00:00<01:06, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 83.9M/9.98G [00:03<04:42, 35.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|     | 126M/9.98G [00:03<03:22, 48.7MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 94.4M/9.98G [00:04<07:44, 21.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 41.9M/3.50G [00:02<03:25, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|     | 136M/9.98G [00:04<08:03, 20.4MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 105M/9.98G [00:04<07:43, 21.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   1%|    | 31.5M/3.50G [00:04<09:21, 6.18MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|     | 147M/9.98G [00:04<06:11, 26.5MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 115M/9.98G [00:04<06:04, 27.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 157M/9.98G [00:04<04:58, 32.9MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 126M/9.98G [00:04<05:03, 32.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 168M/9.98G [00:05<04:43, 34.6MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 136M/9.98G [00:05<05:14, 31.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 178M/9.98G [00:05<04:24, 37.1MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 147M/9.98G [00:05<04:45, 34.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 189M/9.98G [00:05<04:19, 37.7MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 157M/9.98G [00:05<04:09, 39.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 199M/9.98G [00:05<03:38, 44.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   1%|    | 41.9M/3.50G [00:05<08:06, 7.10MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 168M/9.98G [00:05<04:02, 40.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 210M/9.98G [00:06<03:41, 44.1MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 178M/9.98G [00:06<03:42, 44.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 220M/9.98G [00:06<03:17, 49.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 231M/9.98G [00:06<02:55, 55.4MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 189M/9.98G [00:06<03:41, 44.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 52.4M/3.50G [00:03<05:33, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   1%|    | 52.4M/3.50G [00:06<07:03, 8.13MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 199M/9.98G [00:06<04:33, 35.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|     | 241M/9.98G [00:06<04:37, 35.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 252M/9.98G [00:07<06:03, 26.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   2%|    | 62.9M/3.50G [00:07<06:11, 9.26MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 210M/9.98G [00:07<06:55, 23.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 262M/9.98G [00:07<05:29, 29.5MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 220M/9.98G [00:07<05:28, 29.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 273M/9.98G [00:08<05:33, 29.1MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 231M/9.98G [00:08<05:43, 28.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 283M/9.98G [00:08<06:12, 26.0MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 241M/9.98G [00:08<06:15, 25.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 294M/9.98G [00:08<05:05, 31.7MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 252M/9.98G [00:08<05:34, 29.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 304M/9.98G [00:09<04:14, 38.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 62.9M/3.50G [00:06<08:22, 6.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 315M/9.98G [00:09<03:40, 43.9MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 262M/9.98G [00:09<04:47, 33.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 325M/9.98G [00:09<03:19, 48.5MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 273M/9.98G [00:09<04:06, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 283M/9.98G [00:09<03:31, 45.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 336M/9.98G [00:09<03:12, 50.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 73.4M/3.50G [00:06<06:32, 8.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 294M/9.98G [00:09<03:10, 50.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 346M/9.98G [00:09<03:14, 49.6MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 304M/9.98G [00:09<02:57, 54.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   2%|    | 73.4M/3.50G [00:09<08:03, 7.09MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 83.9M/3.50G [00:07<04:59, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 357M/9.98G [00:10<03:18, 48.4MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 315M/9.98G [00:09<02:57, 54.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|    | 94.4M/3.50G [00:07<03:49, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 367M/9.98G [00:10<03:15, 49.2MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 325M/9.98G [00:10<03:00, 53.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 105M/3.50G [00:07<02:57, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 377M/9.98G [00:10<03:17, 48.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   2%|    | 83.9M/3.50G [00:10<06:27, 8.83MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 336M/9.98G [00:10<03:04, 52.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 115M/3.50G [00:07<02:19, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 346M/9.98G [00:10<02:57, 54.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 388M/9.98G [00:10<03:19, 48.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 126M/3.50G [00:07<01:54, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   3%|    | 94.4M/3.50G [00:10<04:54, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 357M/9.98G [00:10<03:00, 53.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 136M/3.50G [00:08<01:35, 35.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 409M/9.98G [00:10<02:49, 56.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 147M/3.50G [00:08<01:22, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 367M/9.98G [00:10<03:01, 53.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 419M/9.98G [00:11<02:49, 56.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 157M/3.50G [00:08<01:11, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 377M/9.98G [00:11<02:50, 56.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   3%|▏    | 105M/3.50G [00:11<04:10, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 388M/9.98G [00:11<02:49, 56.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   3%|▏    | 115M/3.50G [00:11<03:12, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▎    | 178M/3.50G [00:08<00:57, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 398M/9.98G [00:11<02:45, 57.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▎    | 189M/3.50G [00:08<00:53, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   4%|▏    | 126M/3.50G [00:11<02:30, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 199M/3.50G [00:08<00:48, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 409M/9.98G [00:11<02:40, 59.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   4%|▏    | 136M/3.50G [00:11<01:59, 28.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 430M/9.98G [00:11<04:28, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 210M/3.50G [00:09<00:50, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 419M/9.98G [00:11<02:39, 60.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   4%|▏    | 147M/3.50G [00:11<01:47, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 440M/9.98G [00:12<04:26, 35.7MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 430M/9.98G [00:11<02:39, 59.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 220M/3.50G [00:09<01:00, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   4%|▏    | 157M/3.50G [00:12<01:38, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 451M/9.98G [00:12<04:15, 37.3MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 440M/9.98G [00:12<02:51, 55.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 231M/3.50G [00:09<01:09, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 461M/9.98G [00:12<03:42, 42.8MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 451M/9.98G [00:12<02:54, 54.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   5%|▏    | 168M/3.50G [00:12<01:32, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 472M/9.98G [00:12<03:06, 50.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 241M/3.50G [00:09<01:07, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 461M/9.98G [00:12<03:04, 51.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   5%|▎    | 178M/3.50G [00:12<01:26, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 493M/9.98G [00:12<02:22, 66.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 252M/3.50G [00:10<01:07, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 514M/9.98G [00:12<01:54, 82.5MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 472M/9.98G [00:12<03:13, 49.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   5%|▎    | 189M/3.50G [00:12<01:25, 39.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 262M/3.50G [00:10<01:07, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 535M/9.98G [00:13<01:41, 93.0MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 482M/9.98G [00:12<03:12, 49.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎     | 556M/9.98G [00:13<01:27, 107MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   6%|▎    | 199M/3.50G [00:13<01:29, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 273M/3.50G [00:10<01:08, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎     | 577M/9.98G [00:13<01:17, 121MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 493M/9.98G [00:13<03:18, 47.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎     | 598M/9.98G [00:13<01:10, 132MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 283M/3.50G [00:10<01:08, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 503M/9.98G [00:13<03:07, 50.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▍     | 629M/9.98G [00:13<00:58, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   6%|▎    | 210M/3.50G [00:13<01:36, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 294M/3.50G [00:10<01:02, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 514M/9.98G [00:13<02:49, 55.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▍     | 650M/9.98G [00:13<00:57, 161MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 304M/3.50G [00:11<00:58, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 524M/9.98G [00:13<02:52, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 535M/9.98G [00:14<03:37, 43.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 315M/3.50G [00:11<01:39, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   6%|▎    | 220M/3.50G [00:14<02:42, 20.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 325M/3.50G [00:12<01:32, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 671M/9.98G [00:14<02:49, 54.9MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 545M/9.98G [00:14<05:50, 26.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 336M/3.50G [00:12<01:35, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 556M/9.98G [00:15<05:14, 29.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 692M/9.98G [00:16<05:44, 26.9MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 566M/9.98G [00:16<10:46, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 577M/9.98G [00:17<09:14, 16.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 346M/3.50G [00:14<04:43, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 703M/9.98G [00:17<07:18, 21.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 724M/9.98G [00:17<05:17, 29.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 734M/9.98G [00:17<04:34, 33.7MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 587M/9.98G [00:17<08:59, 17.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▌    | 357M/3.50G [00:15<03:50, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 598M/9.98G [00:17<07:03, 22.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 755M/9.98G [00:17<03:27, 44.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▌    | 367M/3.50G [00:15<03:00, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 608M/9.98G [00:18<05:55, 26.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 765M/9.98G [00:18<03:25, 44.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 377M/3.50G [00:15<02:32, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 776M/9.98G [00:18<03:17, 46.5MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 619M/9.98G [00:18<05:37, 27.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 786M/9.98G [00:18<03:23, 45.1MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 629M/9.98G [00:18<05:17, 29.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 797M/9.98G [00:18<03:42, 41.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 807M/9.98G [00:19<03:11, 47.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 388M/3.50G [00:16<02:52, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 818M/9.98G [00:19<03:09, 48.4MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 640M/9.98G [00:19<06:37, 23.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   7%|▎    | 231M/3.50G [00:19<09:39, 5.64MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 398M/3.50G [00:16<02:52, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 650M/9.98G [00:19<05:46, 26.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 828M/9.98G [00:19<04:05, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   7%|▎    | 241M/3.50G [00:19<07:02, 7.71MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 661M/9.98G [00:19<04:48, 32.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 409M/3.50G [00:17<02:25, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   7%|▎    | 252M/3.50G [00:20<05:23, 10.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 671M/9.98G [00:19<04:27, 34.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 419M/3.50G [00:17<01:59, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 839M/9.98G [00:20<04:56, 30.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 430M/3.50G [00:17<01:33, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 682M/9.98G [00:20<03:46, 41.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   7%|▎    | 262M/3.50G [00:20<04:05, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 692M/9.98G [00:20<03:19, 46.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 440M/3.50G [00:17<01:34, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 451M/3.50G [00:18<01:24, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 849M/9.98G [00:20<06:18, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   8%|▍    | 273M/3.50G [00:20<03:43, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 703M/9.98G [00:20<05:23, 28.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 860M/9.98G [00:21<05:39, 26.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 870M/9.98G [00:21<04:38, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 881M/9.98G [00:21<04:23, 34.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 461M/3.50G [00:18<02:09, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 713M/9.98G [00:21<06:14, 24.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 891M/9.98G [00:21<03:45, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 902M/9.98G [00:21<03:09, 47.9MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 724M/9.98G [00:21<05:56, 26.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   8%|▍    | 283M/3.50G [00:22<04:34, 11.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 912M/9.98G [00:22<05:22, 28.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   8%|▍    | 294M/3.50G [00:22<04:01, 13.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 734M/9.98G [00:22<07:41, 20.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 923M/9.98G [00:23<06:20, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   9%|▍    | 304M/3.50G [00:23<03:45, 14.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 933M/9.98G [00:23<05:18, 28.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 472M/3.50G [00:20<04:02, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   9%|▍    | 315M/3.50G [00:23<03:04, 17.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 944M/9.98G [00:23<05:33, 27.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   9%|▍    | 325M/3.50G [00:23<02:39, 19.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 954M/9.98G [00:24<05:19, 28.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  10%|▍    | 336M/3.50G [00:24<02:08, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  10%|▍    | 346M/3.50G [00:24<01:51, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 482M/3.50G [00:21<04:26, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  10%|▌    | 357M/3.50G [00:24<01:40, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 965M/9.98G [00:24<06:13, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  10%|▌    | 367M/3.50G [00:24<01:22, 38.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 744M/9.98G [00:24<14:06, 10.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 493M/3.50G [00:22<03:47, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  11%|▌    | 377M/3.50G [00:25<01:16, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 755M/9.98G [00:25<11:28, 13.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 975M/9.98G [00:25<06:22, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  11%|▌    | 388M/3.50G [00:25<01:11, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 503M/3.50G [00:22<03:08, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 765M/9.98G [00:25<08:45, 17.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  11%|▌    | 398M/3.50G [00:25<01:09, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 776M/9.98G [00:25<06:49, 22.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 986M/9.98G [00:25<06:08, 24.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▋    | 514M/3.50G [00:22<02:35, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 786M/9.98G [00:25<05:19, 28.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 797M/9.98G [00:25<04:41, 32.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▋    | 524M/3.50G [00:23<02:20, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 807M/9.98G [00:25<04:00, 38.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 996M/9.98G [00:26<06:13, 24.0MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 818M/9.98G [00:26<03:20, 45.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  12%|▌    | 409M/3.50G [00:26<01:57, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍   | 1.01G/9.98G [00:26<06:05, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▊    | 535M/3.50G [00:23<02:17, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 828M/9.98G [00:26<03:51, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 839M/9.98G [00:26<03:43, 40.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍   | 1.02G/9.98G [00:26<05:47, 25.8MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 849M/9.98G [00:26<03:37, 41.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍   | 1.03G/9.98G [00:27<04:52, 30.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  12%|▌    | 419M/3.50G [00:27<02:34, 19.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 860M/9.98G [00:27<03:15, 46.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▍   | 1.04G/9.98G [00:27<04:02, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 545M/3.50G [00:24<02:48, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 870M/9.98G [00:27<03:18, 45.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.05G/9.98G [00:27<03:53, 38.2MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 881M/9.98G [00:28<08:43, 17.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.06G/9.98G [00:29<09:55, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.07G/9.98G [00:29<07:58, 18.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.08G/9.98G [00:29<07:10, 20.7MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 891M/9.98G [00:29<10:56, 13.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.09G/9.98G [00:30<08:07, 18.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  12%|▌    | 430M/3.50G [00:30<06:47, 7.54MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.10G/9.98G [00:31<09:50, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  13%|▋    | 440M/3.50G [00:31<06:08, 8.29MB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 902M/9.98G [00:31<14:17, 10.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.11G/9.98G [00:31<07:32, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  13%|▋    | 451M/3.50G [00:31<04:38, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.12G/9.98G [00:31<06:05, 24.2MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 912M/9.98G [00:31<11:22, 13.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.13G/9.98G [00:32<05:13, 28.2MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 923M/9.98G [00:31<08:56, 16.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  13%|▋    | 461M/3.50G [00:32<03:51, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  13%|▋    | 472M/3.50G [00:32<03:02, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  14%|▋    | 482M/3.50G [00:32<02:17, 22.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▍   | 1.14G/9.98G [00:32<06:02, 24.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▍   | 1.15G/9.98G [00:32<04:51, 30.3MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 933M/9.98G [00:32<09:29, 15.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  14%|▋    | 493M/3.50G [00:32<02:19, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Fetching 16 files:  38%|█████████▍               | 6/16 [00:33<00:55,  5.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 556M/3.50G [00:31<11:04, 4.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[ATraceback (most recent call last):\n",
      "  File \"/opt/conda/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
      "    service.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/download.py\", line 161, in run\n",
      "    print(self._download())  # Print path to downloaded files\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/download.py\", line 202, in _download\n",
      "    return snapshot_download(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 119, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py\", line 316, in snapshot_download\n",
      "    thread_map(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
      "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
      "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 621, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 319, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py\", line 290, in _inner_hf_hub_download\n",
      "    return hf_hub_download(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 119, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1492, in hf_hub_download\n",
      "    http_get(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 538, in http_get\n",
      "    temp_file.write(chunk)\n",
      "  File \"/opt/conda/lib/python3.10/tempfile.py\", line 483, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "model-00001-of-00002.safetensors:  12%|▍   | 1.16G/9.98G [00:33<04:16, 34.3MB/s]\n",
      "model-00002-of-00002.safetensors:  14%|▋    | 493M/3.50G [00:33<03:26, 14.6MB/s]\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 933M/9.98G [00:33<05:26, 27.7MB/s]\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 556M/3.50G [00:31<02:45, 17.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download meta-llama/Llama-2-7b-chat-hf --local-dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83eba3-d552-41e5-bfa1-6b280476f198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
